{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90641074",
   "metadata": {},
   "source": [
    "# Welcome to the AI powered Travel Lodging website pipeline!!!\n",
    "Below you will find the steps we used to generate the requirements, documentation\n",
    "and initial code for the application.\n",
    "\n",
    "  \n",
    "**Common Setup for the pipeline...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    # Assumes the notebook is in one folder below.\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, clean_llm_output, load_artifact, render_plantuml_diagram\n",
    "\n",
    "# Initialize the LLM client. You can change the model here.\n",
    "# For example: setup_llm_client(model_name=\"gemini-2.5-flash\")\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217275de",
   "metadata": {},
   "source": [
    "**Generate the PRD**\n",
    "1. Created a problem_statement prompt with the high level purpose of the application.\n",
    "2. Created a PRD prompt, limiting the scope to our MVP features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35616880",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate the PRD\n",
    "\n",
    "problem_statement = f\"\"\"\n",
    "We want to write a simple application that connects users to vacation rentals. \n",
    "The application should allow users to get a recommendation for vacation rentals based on \n",
    "their desired activities and/or attractions they wish to visit.\n",
    "\n",
    "Users will have the ability to make a reservation at their selected property.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prd_prompt = f\"\"\"# Generate a Product Requirements Document (PRD) for the following problem statement:\n",
    "{problem_statement} \n",
    "# The PRD should include the following sections:\n",
    "1. **Problem Statement**: A clear and concise description of the problem.  \n",
    "2. **Objectives**: The goals we want to achieve with this application.\n",
    "3. **User Stories**: A list of user stories that describe the features from the user's perspective.\n",
    "4. **Acceptance Criteria**: The criteria that must be met for the user stories to be considered complete.\n",
    "5. **Out of Scope**: Features that are not included in the initial release.\n",
    "\n",
    " # We are focused on the initial MVP (Minimum Viable Product) and will include only the essential features.\n",
    "    1. User can specify a list of activities or attractions they want to visit.\n",
    "    2. User can get a recommendation for vacation rentals based on their desired activities or attractions\n",
    "    3. User can make a reservation at their selected property.\n",
    "\n",
    "# The PRD should be in Markdown format and should be well-structured.\n",
    "  The PRD should be concise and to the point, avoiding unnecessary details.\n",
    "    \n",
    "  \"\"\"  \n",
    "\n",
    "print(\"--- Generating  PRD ---\")\n",
    "\n",
    "prd_output = get_completion(prd_prompt, client, model_name, api_provider)\n",
    "prd_output_clean = clean_llm_output(prd_output, \"markdown\")\n",
    "save_artifact( prd_output_clean, \"capstone_artifacts/prd.md\",)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc723a4",
   "metadata": {},
   "source": [
    "**Generate the database schema**\n",
    "1. Created a schema prompt with specifics on the three tables we wanted, and their key attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625f57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the PRD content for schema generation\n",
    "prd_content = load_artifact(\"capstone_artifacts/prd.md\")\n",
    "schema_prompt = f\"\"\"\n",
    "You are an expert Database Administrator.\n",
    "Using this PRD as a reference: {prd_content}\n",
    "From this PRD, create a normalized SQL schema with only the following three tables:\n",
    "1. **Users**: To store user information and their interests\n",
    "2. **Properties**: To store vacation rental properties located in the US.  Include fields for full address.\n",
    "        No need for latititude/longitude info.\n",
    "3. **Reservations**: To store user reservations for properties.\n",
    "The output should be the raw `CREATE TABLE` statements.  SQL should be compatible with sqllite3.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating SQL Schema ---\")\n",
    "if prd_content:\n",
    "    generated_schema = get_completion(schema_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated schema using our helper function\n",
    "    cleaned_schema = clean_llm_output(generated_schema, language='sql')\n",
    "    print(cleaned_schema)\n",
    "    \n",
    "    # Save the cleaned schema\n",
    "    save_artifact(cleaned_schema, 'capstone_artifacts/schema.sql')\n",
    "else:\n",
    "    print(\"Skipping schema generation because PRD is missing.\")\n",
    "    cleaned_schema = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b1c270",
   "metadata": {},
   "source": [
    "**Generate Seed Data**\n",
    "1. Started with an initial prompt that was only getting us User data.\n",
    "2. Took our prompt and fed that into CoPilot asking for recommendations for improvement, and we used that as our final prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e9a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_schema = load_artifact('capstone_artifacts/schema.sql')\n",
    "prd_content = load_artifact('capstone_artifacts/prd.md')\n",
    "# TODO: Write a prompt to generate realistic seed data.\n",
    "\n",
    "seed_data_prompt = f\"\"\"You are a senior-level Database Engineer with deep expertise in data modeling, SQL, and realistic data generation.\n",
    "\n",
    "Use the following Product Requirements Document (PRD) as domain context: {prd_content}\n",
    "\n",
    "Use the following SQLite-compatible schema as the structural reference: {cleaned_schema}\n",
    "\n",
    "Your task is to generate seed data for a vacation rental system. The output should consist of pure SQL `INSERT INTO` statements, compatible with SQLite3, with no explanation or additional formatting.\n",
    "\n",
    "Generate seed data for the following tables:\n",
    "\n",
    "1. **Users**\n",
    "   - Insert at least 10 realistic users.\n",
    "   - Include a variety of demographics (age, gender, region) and interests (e.g., hiking, food, culture).\n",
    "   - Make sure the data reflects diverse travel preferences.\n",
    "\n",
    "2. **Properties**\n",
    "   - Insert at least 100 vacation rental properties.\n",
    "   - Each property should include a full US address (street, city, state, zip).\n",
    "   - Include amenities such as Wi-Fi, pool, pet-friendly, etc.\n",
    "   - Distribute properties across a mix of major cities (e.g., NYC, LA, Chicago) and rural destinations (e.g., Sedona, Lake Tahoe, Smoky Mountains).\n",
    "\n",
    "3. **Reservations**\n",
    "   - Insert at least 5 sample reservations.\n",
    "   - Link existing users to properties with reasonable travel dates.\n",
    "   - Avoid date conflicts or duplicates.\n",
    "   - Include a mix of short and longer stays, seasonal variation, and different users.\n",
    "\n",
    "Ensure all foreign key relationships are valid, and all timestamps and locations make sense in context.\n",
    "\n",
    "Return only the SQL seed statements ‚Äî no commentary, no markdown, no code fencing.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"--- Generating Seed Data ---\")\n",
    "if prd_content and cleaned_schema:\n",
    "    generated_seed_data = get_completion(seed_data_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated seed data\n",
    "    cleaned_seed_data = clean_llm_output(generated_seed_data, language='sql')\n",
    "    print(cleaned_seed_data)\n",
    "    \n",
    "    # Save the cleaned seed data\n",
    "    save_artifact(cleaned_seed_data, 'capstone_artifacts/seed_data.sql')\n",
    "else:\n",
    "    print(\"Skipping seed data generation because PRD or schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aedeb9",
   "metadata": {},
   "source": [
    "**Generate Architecture Documentation**\n",
    "1. Started with our own prompt and got back more of compenent diagram in text format, rather than an architecture document.\n",
    "2. Took our prompt and fed that into CoPilot asking for recommendations for improvement, and we used that as our final prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26baf297",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = load_artifact('capstone_artifacts/schema.sql')\n",
    "prd_content = load_artifact('capstone_artifacts/prd.md')\n",
    "\n",
    "arch_doc_prompt = f\"\"\"\n",
    "You are a seasoned Solution Architect with expertise in designing scalable, modular web applications.\n",
    "\n",
    "Your task is to generate a well-structured, high-level **Architecture Document** in Markdown format for a vacation rental platform. Base your design on:\n",
    "\n",
    "- Product Requirements Document (PRD): {prd_content}\n",
    "- Database Schema (SQLite-compatible): {cleaned_schema}\n",
    "\n",
    "Your document should include the following sections:\n",
    "\n",
    "---\n",
    "\n",
    "1. **Overview**\n",
    "   - Provide a brief summary of the system‚Äôs purpose, primary user personas, and key business goals.\n",
    "   - Highlight any constraints (tech stack, budget, timeline) or assumptions.\n",
    "\n",
    "2. **User Interface**\n",
    "   - Describe the main UI components and user flows: searching rentals, filtering by interests, making reservations.\n",
    "   - Specify technologies: React + Tailwind CSS.\n",
    "   - Mention responsiveness, accessibility, and interaction patterns (e.g. modals, forms, map integrations).\n",
    "\n",
    "3. **Backend Services**\n",
    "   - Detail API endpoints and service responsibilities: user authentication, reservation logic, property search.\n",
    "   - Note use of Python with FastAPI.\n",
    "   - Explain service modularity, request routing, data validation, and async processing (if applicable).\n",
    "\n",
    "4. **Database Design**\n",
    "   - Summarize the schema structure: tables, relationships, constraints, indexes.\n",
    "   - Address how user, property, and reservation data are stored and queried.\n",
    "   - Call out any SQLite-specific design considerations (e.g. lack of native concurrency or full-text search).\n",
    "\n",
    "5. **Property Recommendation Engine**\n",
    "   - Explain how user interests are captured and interpreted.\n",
    "   - Describe how an LLM will be used to match users to relevant properties.\n",
    "   - Include input/output formats, example prompt flow, and scoring or filtering strategies.\n",
    "\n",
    "6. **Deployment & DevOps (Optional)**\n",
    "   - Mention local development setup, environment configuration, and deployment pipeline (if relevant).\n",
    "   - Could include use of Docker, CI/CD tools, or cloud platforms.\n",
    "\n",
    "---\n",
    "\n",
    "Output only the Markdown document ‚Äî no extra commentary or formatting. Ensure it reads clearly for technical and non-technical stakeholders.\n",
    "\n",
    "\n",
    "\"\"\"    \n",
    "\n",
    "print(\"--- Generating Architecture Doc ---\")\n",
    "if schema and prd_content:\n",
    "    generated_arch_doc = get_completion(arch_doc_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated architecture document\n",
    "    cleaned_arch_doc = clean_llm_output(generated_arch_doc, \"markdown\")\n",
    "    \n",
    "    # Save the cleaned seed data\n",
    "    save_artifact(cleaned_arch_doc, 'capstone_artifacts/architecture_doc.md')\n",
    "else:\n",
    "    print(\"Skipping architecture doce generation because PRD or schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7005d9c0",
   "metadata": {},
   "source": [
    "**Generate UML Component Diagram**\n",
    "1. Created our own prompt, specifying the components we wanted to see on the diagram.\n",
    "2. Ran into an issue with the generated plantuml containing some invalid class defintion.\n",
    "3. Updated the prompt specifying to not include any class definitions and then it succeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f17d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_doc = load_artifact('capstone_artifacts/architecture_doc.md')\n",
    "\n",
    "# Generate a component diagram for the architecture document\n",
    "component_diagram_prompt = \"\"\"\n",
    "You are an expert system architect. Generate PlantUML code for a component diagram that describes \n",
    "a web application architecture for a vacation rental platform based on the following requirements:\n",
    "\n",
    "The diagram should include the following four components:\n",
    "- A 'Frontend' (e.g., a web browser)\n",
    "- A 'Backend API Server'\n",
    "- A 'LLM-based Recommendation Engine'\n",
    "- A 'Database'\n",
    "\n",
    "The relationships are as follows:\n",
    "- The Frontend communicates with the Backend API Server over HTTPS for tasks like view assigned tasks for users and create tasks for admins.\n",
    "- The Backend API Server reads from and writes to the Database.\n",
    "- The Backend API Server sends requests to the LLM-based Recommendation Engine to get property \n",
    "    recommendations based on user interests.\n",
    "\n",
    "Do not generate or include any custom classes in the output.\n",
    "Output only the raw PlantUML code inside a markdown block.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Component Diagram ---\")\n",
    "component_puml_raw = get_completion(component_diagram_prompt, client, model_name, api_provider)\n",
    "component_puml = clean_llm_output(component_puml_raw, language='plantuml')\n",
    "\n",
    "print(\"\\n--- Generated PlantUML Code ---\")\n",
    "print(component_puml)\n",
    "if component_puml:\n",
    "    save_artifact(component_puml, 'capstone_artifacts/app_component_diagram.puml')\n",
    "\n",
    "# Render the diagram\n",
    "if component_puml:\n",
    "    render_plantuml_diagram(component_puml, \"capstone_artifacts/app_component_diagram.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585660f0",
   "metadata": {},
   "source": [
    "**Code block to create and seed the database, using previously generated scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6785d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the SQLite database and seed it with data\n",
    "# This code will create a SQLite database file and populate it with the schema and seed data generated\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "def create_database(db_path, schema_path, seed_path):\n",
    "    \"\"\"Creates and seeds a SQLite database from SQL files.\"\"\"\n",
    "    if not os.path.exists(schema_path):\n",
    "        print(f\"Error: Schema file not found at {schema_path}\")\n",
    "        return\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        # TODO: Connect to the SQLite database. This will create the file if it doesn't exist.\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        print(f\"Successfully connected to database at {db_path}\")\n",
    "\n",
    "        # TODO: Read the content of the schema file using load_artifact.\n",
    "        schema_sql = load_artifact(schema_path)\n",
    "        \n",
    "        # TODO: Execute the schema SQL script.\n",
    "        # Hint: Use cursor.executescript() for multi-statement SQL strings.\n",
    "        cursor.executescript(schema_sql)\n",
    "        \n",
    "        print(\"Tables created successfully.\")\n",
    "\n",
    "        # TODO: Check if the seed data file exists. If it does, load and execute it.\n",
    "        if os.path.exists(seed_path):\n",
    "            insert_sql = load_artifact(seed_path)\n",
    "            # pass # Your code here\n",
    "            cursor.executescript(insert_sql)\n",
    "\n",
    "        # TODO: Commit the changes to the database.\n",
    "        conn.commit()\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "    finally:\n",
    "        # TODO: Ensure the connection is closed if it was opened.\n",
    "        conn.close() # Your code here\n",
    "\n",
    "# Define file paths\n",
    "db_file = os.path.join(project_root, \"app\", \"travel.db\")\n",
    "schema_file = os.path.join(project_root, \"capstone_artifacts\", \"schema.sql\")\n",
    "seed_file = os.path.join(project_root, \"capstone_artifacts\", \"seed_data.sql\")\n",
    "\n",
    "# Execute the function\n",
    "create_database(db_file, schema_file, seed_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9203336f",
   "metadata": {},
   "source": [
    "**Generate FastAPI backend API with Pydantic and SQLAlchemy models\"\n",
    "1. Started with our own prompt to generate the code.\n",
    "2. Based on the lab, we knew there was a potential for class name clashes so we asked to create separte python files for each.\n",
    "3. Fed our prompt into CoPilot to reword so that we could separate out the 3 python files, and so the main api would import the Pydantic and SQLAlchemy modules.\n",
    "4. Based on the response from CoPilot, we asked it go generate function to parse out the individual python files from the response -> `parse_and_save_scripts()`  \n",
    "Added the database connection info the generated prompt prior to running the LLM to generate the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d3bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_and_save_scripts(llm_output: str, output_dir: str = \".\"):\n",
    "    # Regex pattern to capture file delimiter and content\n",
    "    pattern = r\"# FILE: (?P<filename>[^\\n]+)\\n(?P<content>.*?)(?=\\n# FILE:|\\Z)\"\n",
    "\n",
    "    matches = re.finditer(pattern, llm_output, re.DOTALL)\n",
    "\n",
    "    for match in matches:\n",
    "        filename = match.group(\"filename\").strip()\n",
    "        content = match.group(\"content\").strip()\n",
    "\n",
    "        filepath = f\"{output_dir}/{filename}\"\n",
    "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content + \"\\n\")\n",
    "\n",
    "        print(f\"‚úÖ Saved {filename}\")\n",
    "\n",
    "\n",
    "sql_schema = load_artifact('capstone_artifacts/schema.sql')\n",
    "api_prompt = f\"\"\"\n",
    "You are a senior-level Python developer with deep expertise in FastAPI, Pydantic, and SQLAlchemy.\n",
    "\n",
    "Using the following SQLite-compatible database schema: {sql_schema}\n",
    "\n",
    "Your task is to generate three complete and distinct Python scripts, each representing a different layer of the system architecture. Each script should include all necessary imports and be syntactically valid for direct use.\n",
    "\n",
    "---\n",
    "\n",
    "### üìÅ Structure of Output\n",
    "Please output each script using clear and consistent file delimiters so it can be easily extracted into separate files.\n",
    "\n",
    "Use this format:\n",
    "\n",
    "#### `# FILE: models_pydantic.py`\n",
    "<-- Pydantic models for request and response validation go here -->\n",
    "\n",
    "#### `# FILE: models_sqlalchemy.py`\n",
    "<-- SQLAlchemy ORM models representing the database schema go here -->\n",
    "\n",
    "#### `# FILE: api_endpoints.py`\n",
    "<-- FastAPI routes implementing full CRUD for each table go here -->\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Requirements for Each File\n",
    "\n",
    "#### üîπ Pydantic Models (`models_pydantic.py`)\n",
    "- Define request and response schemas using `BaseModel`.\n",
    "- Include typing hints and field validation if applicable.\n",
    "\n",
    "#### üîπ SQLAlchemy Models (`models_sqlalchemy.py`)\n",
    "- Map all database tables from the schema using SQLAlchemy‚Äôs declarative base.\n",
    "- Include relationships, indexes, constraints as appropriate.\n",
    "- Ensure the code is compatible with SQLite.\n",
    "- set DATABASE_URL = \"sqlite:///./travel.db\"\n",
    "\n",
    "#### üîπ FastAPI Endpoints (`api_endpoints.py`)\n",
    "- Use FastAPI to define routes for Create, Read, Update, Delete operations.\n",
    "- Include imports for `FastAPI`, models, and session handling.\n",
    "- Ensure endpoints reference both SQLAlchemy and Pydantic models properly.\n",
    "- Assume a working SQLite database and session setup.\n",
    "\n",
    "Return only the code content using the `# FILE:` delimiters ‚Äî no explanations, markdown formatting, or additional commentary.\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating FastAPI app ---\")\n",
    "if sql_schema:\n",
    "    generated_api_code = get_completion(api_prompt, client, model_name, api_provider)\n",
    "    cleaned_code = clean_llm_output(generated_api_code, language='python')\n",
    "    parse_and_save_scripts(cleaned_code, output_dir=\"../app\")\n",
    "else:\n",
    "    print(\"Skipping API generation because schema is missing.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088c589e",
   "metadata": {},
   "source": [
    "**Running the API**  \n",
    "  \n",
    "From a terminal/command prompt, with the proper python enviornment activated, run the following command:   \n",
    "`uvicorn api_endpoints:app --reload`\n",
    "\n",
    "The output of the command should indicate where the API is running.  \n",
    "Example: `Uvicorn running on http://127.0.0.1:8000`\n",
    "\n",
    "From a web browser, navigate to that address, appending `/docs` to the url to access the API.  \n",
    "Example: `http://127.0.0.1:8000/docs`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
